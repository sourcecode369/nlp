{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntry:\n   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  \n   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nexcept ValueError:\n   tpu = None\nif tpu:\n   tf.config.experimental_connect_to_cluster(tpu)\n   tf.tpu.experimental.initialize_tpu_system(tpu)\n   strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n   strategy = tf.distribute.get_strategy()","execution_count":1,"outputs":[{"output_type":"stream","text":"Running on TPU  ['10.0.0.2:8470']\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version nightly  --apt-packages libomp5 libopenblas-dev","execution_count":2,"outputs":[{"output_type":"stream","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  5115  100  5115    0     0  18600      0 --:--:-- --:--:-- --:--:-- 18600\nUpdating... This may take around 2 minutes.\nUpdating TPU runtime to pytorch-nightly ...\nFound existing installation: torch 1.5.0\nUninstalling torch-1.5.0:\n  Successfully uninstalled torch-1.5.0\nFound existing installation: torchvision 0.6.0a0+35d732a\nUninstalling torchvision-0.6.0a0+35d732a:\nDone updating TPU runtime\n  Successfully uninstalled torchvision-0.6.0a0+35d732a\nCopying gs://tpu-pytorch/wheels/torch-nightly-cp37-cp37m-linux_x86_64.whl...\n\\ [1 files][110.1 MiB/110.1 MiB]                                                \nOperation completed over 1 objects/110.1 MiB.                                    \nCopying gs://tpu-pytorch/wheels/torch_xla-nightly-cp37-cp37m-linux_x86_64.whl...\n\\ [1 files][127.2 MiB/127.2 MiB]                                                \nOperation completed over 1 objects/127.2 MiB.                                    \nCopying gs://tpu-pytorch/wheels/torchvision-nightly-cp37-cp37m-linux_x86_64.whl...\n/ [1 files][  2.4 MiB/  2.4 MiB]                                                \nOperation completed over 1 objects/2.4 MiB.                                      \nProcessing ./torch-nightly-cp37-cp37m-linux_x86_64.whl\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (1.18.5)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (0.18.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==nightly) (3.7.4.1)\n\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n\u001b[31mERROR: kornia 0.3.1 has requirement torch==1.5.0, but you'll have torch 1.7.0a0+b6810c1 which is incompatible.\u001b[0m\n\u001b[31mERROR: allennlp 1.0.0 has requirement torch<1.6.0,>=1.5.0, but you'll have torch 1.7.0a0+b6810c1 which is incompatible.\u001b[0m\nInstalling collected packages: torch\nSuccessfully installed torch-1.7.0a0+b6810c1\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\nProcessing ./torch_xla-nightly-cp37-cp37m-linux_x86_64.whl\nInstalling collected packages: torch-xla\nSuccessfully installed torch-xla-1.6+2c732f2\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\nProcessing ./torchvision-nightly-cp37-cp37m-linux_x86_64.whl\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (1.7.0a0+b6810c1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (1.18.5)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly) (7.2.0)\nRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly) (0.18.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly) (3.7.4.1)\nInstalling collected packages: torchvision\nSuccessfully installed torchvision-0.8.0a0+a75fdd4\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  libgfortran4 libopenblas-base\nThe following NEW packages will be installed:\n  libgfortran4 libomp5 libopenblas-base libopenblas-dev\n0 upgraded, 4 newly installed, 0 to remove and 59 not upgraded.\nNeed to get 8550 kB of archives.\nAfter this operation, 97.6 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libgfortran4 amd64 7.5.0-3ubuntu1~18.04 [492 kB]\nGet:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-base amd64 0.2.20+ds-4 [3964 kB]\nGet:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenblas-dev amd64 0.2.20+ds-4 [3860 kB]\nGet:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\nFetched 8550 kB in 1s (6198 kB/s) \ndebconf: delaying package configuration, since apt-utils is not installed\nSelecting previously unselected package libgfortran4:amd64.\n(Reading database ... 107745 files and directories currently installed.)\nPreparing to unpack .../libgfortran4_7.5.0-3ubuntu1~18.04_amd64.deb ...\nUnpacking libgfortran4:amd64 (7.5.0-3ubuntu1~18.04) ...\nSelecting previously unselected package libopenblas-base:amd64.\nPreparing to unpack .../libopenblas-base_0.2.20+ds-4_amd64.deb ...\nUnpacking libopenblas-base:amd64 (0.2.20+ds-4) ...\nSelecting previously unselected package libopenblas-dev:amd64.\nPreparing to unpack .../libopenblas-dev_0.2.20+ds-4_amd64.deb ...\nUnpacking libopenblas-dev:amd64 (0.2.20+ds-4) ...\nSelecting previously unselected package libomp5:amd64.\nPreparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\nUnpacking libomp5:amd64 (5.0.1-1) ...\nSetting up libomp5:amd64 (5.0.1-1) ...\nSetting up libgfortran4:amd64 (7.5.0-3ubuntu1~18.04) ...\nSetting up libopenblas-base:amd64 (0.2.20+ds-4) ...\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 to provide /usr/lib/x86_64-linux-gnu/libblas.so.3 (libblas.so.3-x86_64-linux-gnu) in auto mode\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so.3 to provide /usr/lib/x86_64-linux-gnu/liblapack.so.3 (liblapack.so.3-x86_64-linux-gnu) in auto mode\nSetting up libopenblas-dev:amd64 (0.2.20+ds-4) ...\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/libblas.so to provide /usr/lib/x86_64-linux-gnu/libblas.so (libblas.so-x86_64-linux-gnu) in auto mode\nupdate-alternatives: using /usr/lib/x86_64-linux-gnu/openblas/liblapack.so to provide /usr/lib/x86_64-linux-gnu/liblapack.so (liblapack.so-x86_64-linux-gnu) in auto mode\nProcessing triggers for libc-bin (2.27-3ubuntu1) ...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n%autosave 60\n\nimport os\nos.environ['XLA_USE_BF16'] = \"1\"\nos.environ['XLA_TENSOR_ALLOCATOR_MAXSIZE'] = '100000000'\n\nimport gc\ngc.enable()\nimport time\nimport random \n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm \n\nimport transformers\nfrom transformers import (AdamW, \n                          XLMRobertaTokenizer, \n                          XLMRobertaModel, \n                          get_cosine_schedule_with_warmup)\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.distributed import DistributedSampler\n\nimport torch_xla\nimport torch_xla.core.xla_model as xm\nimport torch_xla.debug.metrics as met\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.utils.serialization as xser\nimport torch_xla.version as xv\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nprint('PYTORCH:', xv.__torch_gitrev__)\nprint('XLA:', xv.__xla_gitrev__)","execution_count":3,"outputs":[{"output_type":"display_data","data":{"application/javascript":"IPython.notebook.set_autosave_interval(60000)"},"metadata":{}},{"output_type":"stream","text":"Autosaving every 60 seconds\n","name":"stdout"},{"output_type":"stream","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n","name":"stderr"},{"output_type":"stream","text":"PYTORCH: b6810c1064eb24cb542a9be56140689dce8ad7a1\nXLA: 2c732f20b5343dd1a694cd69cd15dd7f76ee1028\nCPU times: user 1.43 s, sys: 215 ms, total: 1.65 s\nWall time: 2.5 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/contradictory-my-dear-watson/train.csv')\ntest = pd.read_csv('../input/contradictory-my-dear-watson/test.csv')\nsample_submission = pd.read_csv('../input/contradictory-my-dear-watson/sample_submission.csv')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(data, sort, tokenizer):\n    sentences = list()\n    texts = data[['premise','hypothesis']].values.tolist()\n    labels = data.label\n    \n    for (text, label) in zip(texts, labels):\n        text = \" \".join(text)\n        ids = tokenizer.encode(text,\n                               add_special_tokens=True,\n                              )\n        lab = len(ids)\n        sentences.append((lab, text, label))\n    if sort:\n        sentences.sort(key=lambda x: x[0])\n    return sentences\n\ndef build_batches(sentences, batch_size):\n    batch_ordered_sentences = list()\n    while len(sentences) > 0:\n        to_take = min(batch_size, len(sentences))\n        select = random.randint(0, len(sentences) - to_take)\n        batch_ordered_sentences += sentences[select:select + to_take]\n        del sentences[select:select + to_take]\n    return batch_ordered_sentences\n\nclass TextDataset(Dataset):\n    def __init__(self,\n                 data,\n                 tokenizer,\n                 max_length):       \n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_len = max_length\n\n    def encode(self, example):\n        encoded_dict = self.tokenizer.encode_plus(text=example,\n                                                  padding=False,\n                                                  truncation=True,\n                                                  add_special_tokens=True,\n                                                  max_length=self.max_len,\n                                                  pad_to_max_length=False,\n                                                  return_token_type_ids=False,\n                                                  return_attention_mask=False,\n                                                  return_position_ids=False,\n                                                  return_overflowing_tokens=False,\n                                                  return_special_tokens_mask=False,\n                                                 )\n        return encoded_dict['input_ids']\n\n    def __getitem__(self, idx):\n        data = self.data[idx]\n        lab, text, label = data\n        ids = self.encode(text)\n        return ids, label\n\n    def __len__(self):\n        return len(self.data)\n    \ndef pad_seq(seq, max_batch_len, pad_value):\n    return seq + (max_batch_len - len(seq)) * [pad_value]\n\ndef collate_batch(batch):\n    batch_inputs = list()\n    batch_attention_masks = list()\n    batch_labels = list()\n    input_ids, labels = zip(*batch)\n    max_size = max([len(ids) for ids in input_ids])\n    for (ids, label) in zip(input_ids, labels):\n        batch_inputs += [pad_seq(ids, max_size, tokenizer.pad_token_id)]\n        batch_attention_masks += [[1] * len(ids) + [0] * (max_size - len(ids))]\n        batch_labels.append(label)\n    return {\"input_ids\": torch.tensor(batch_inputs),\n            \"attention_mask\": torch.tensor(batch_attention_masks),\n            \"labels\": torch.tensor(batch_labels)\n            }","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class XLMRoberta(nn.Module):\n    def __init__(self, num_labels, multisample):\n        super(XLMRoberta, self).__init__()\n        output_hidden_states = False\n        self.num_labels = num_labels\n        self.multisample= multisample\n        self.roberta = XLMRobertaModel.from_pretrained(\"xlm-roberta-base\", \n                                                       output_hidden_states=output_hidden_states, \n                                                       num_labels=1)\n        self.layer_norm = nn.LayerNorm(768*2)\n        self.dropout = nn.Dropout(p=0.2)\n        self.high_dropout = nn.Dropout(p=0.5)        \n        self.classifier = nn.Linear(768*2, self.num_labels)\n    \n    def forward(self,\n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        position_ids=None,\n        head_mask=None,\n        inputs_embeds=None):\n        outputs = self.roberta(input_ids,\n                               attention_mask=attention_mask,\n                               token_type_ids=token_type_ids,\n                               position_ids=position_ids,\n                               head_mask=head_mask,\n                               inputs_embeds=inputs_embeds)\n        average_pool = torch.mean(outputs[0], 1)\n        max_pool, _ = torch.max(outputs[0], 1)\n        concatenate_layer = torch.cat((average_pool, max_pool), 1)\n        normalization = self.layer_norm(concatenate_layer)\n        if self.multisample:\n            # Multisample Dropout\n            logits = torch.mean(\n                torch.stack(\n                    [self.classifier(self.dropout(normalization)) for _ in range(5)],\n                    dim=0,\n                ),\n                dim=0,\n            )\n        else:\n            logits = self.dropout(normalization)\n            logits = self.classifier(logits)       \n        outputs = logits\n        return outputs  ","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter(object):\n    def __init__(self, name, fmt=':f'):\n        self.name = name\n        self.fmt = fmt\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n    def __str__(self):\n        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n        return fmtstr.format(**self.__dict__)\n\nclass ProgressMeter(object):\n    def __init__(self, num_batches, meters, prefix=\"\"):\n        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n        self.meters = meters\n        self.prefix = prefix\n\n    def display(self, batch):\n        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n        entries += [str(meter) for meter in self.meters]\n        print('\\t'.join(entries))\n\n    def _get_batch_fmtstr(self, num_batches):\n        num_digits = len(str(num_batches // 1))\n        fmt = '{:' + str(num_digits) + 'd}'\n        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n\ndef accuracy(output, target, topk=(1,)):\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        _, pred = output.topk(maxk, 1, True, True)\n        pred = pred.t()\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 / batch_size))\n        return res","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model_optimizer(model):\n    # Differential Learning Rate\n    def is_backbone(name):\n        return \"roberta\" in name\n    \n    optimizer_grouped_parameters = [\n       {'params': [param for name, param in model.named_parameters() if is_backbone(name)], 'lr': LR},\n       {'params': [param for name, param in model.named_parameters() if not is_backbone(name)], 'lr': 1e-3} \n    ]\n    \n    optimizer = AdamW(\n        optimizer_grouped_parameters, lr=LR, weight_decay=1e-2\n    )\n    \n    return optimizer","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return nn.CrossEntropyLoss()(outputs, targets)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_loop_fn(train_loader, model, optimizer, device, scheduler, epoch=None):\n    # Train\n    batch_time = AverageMeter('Time', ':6.3f')\n    data_time = AverageMeter('Data', ':6.3f')\n    losses = AverageMeter('Loss', ':.4e')\n    top1 = AverageMeter('Acc@1', ':6.2f')\n    progress = ProgressMeter(\n        len(train_loader),\n        [batch_time, data_time, losses, top1],\n        prefix=\"[xla:{}]Train:  Epoch: [{}]\".format(xm.get_ordinal(), epoch)\n    )\n    model.train()\n    end = time.time()\n    for i, data in enumerate(train_loader):\n        data_time.update(time.time()-end)\n        ids = data[\"input_ids\"]\n        mask = data[\"attention_mask\"]\n        targets = data[\"labels\"]\n        ids = ids.to(device, dtype=torch.long)\n        mask = mask.to(device, dtype=torch.long)\n        targets = targets.to(device, dtype=torch.float)\n        optimizer.zero_grad()\n        outputs = model(\n            input_ids = ids,\n            attention_mask = mask\n        )\n        loss = loss_fn(outputs, targets)\n        loss.backward()\n        xm.optimizer_step(optimizer)\n        loss = loss_fn(outputs, targets)\n        acc1= accuracy(outputs, targets, topk=(1,))\n        losses.update(loss.item(), ids.size(0))\n        top1.update(acc1[0].item(), ids.size(0))\n        scheduler.step()\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if i % 10 == 0:\n            progress.display(i)\n    del loss\n    del outputs\n    del ids\n    del mask\n    del targets\n    gc.collect()","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_loop_fn(validation_loader, model, device):\n    #Validation\n    model.eval()\n    batch_time = AverageMeter('Time', ':6.3f')\n    losses = AverageMeter('Loss', ':.4e')\n    top1 = AverageMeter('Acc@1', ':6.2f')\n    learning_rate = AverageMeter('LR',':2.8f')\n    progress = ProgressMeter(\n        len(validation_loader),\n        [batch_time, losses, top1],\n        prefix='[xla:{}]Validation: '.format(xm.get_ordinal()))\n    with torch.no_grad():\n        end = time.time()\n        for i, data in enumerate(validation_loader):\n            ids = data[\"input_ids\"]\n            mask = data[\"attention_mask\"]\n            targets = data[\"labels\"]\n            ids = ids.to(device, dtype=torch.long)\n            mask = mask.to(device, dtype=torch.long)\n            targets = targets.to(device, dtype=torch.float)\n            outputs = model(\n                input_ids = ids,\n                attention_mask = mask\n            )\n            loss = loss_fn(outputs, targets)\n            acc1= accuracy(outputs, targets, topk=(1,))\n            losses.update(loss.item(), ids.size(0))\n            top1.update(acc1[0].item(), ids.size(0))\n            batch_time.update(time.time() - end)\n            end = time.time()\n            if i % 10 == 0:\n                progress.display(i)\n    del loss\n    del outputs\n    del ids\n    del mask\n    del targets\n    gc.collect()","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 16\nEPOCHS = 15\nMAX_LEN = 96\n# Scale learning rate to 8 TPU's\nLR = 2e-5 * xm.xrt_world_size() \nMETRICS_DEBUG = True\n\nWRAPPED_MODEL = xmp.MpModelWrapper(XLMRoberta(num_labels=3, multisample=False))\ntokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')","execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=512.0, style=ProgressStyle(description_…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae8585c92cc149999b5a49cf9bac5cc9"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1115590446.0, style=ProgressStyle(descr…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2b06a562e6149048910de4c5d1d3655"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5069051.0, style=ProgressStyle(descript…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edf8f396701845f881bd1e70062458cf"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = np.random.rand(len(train)) < 0.95\ntrain_df = train[mask]\nvalid_df = train[~mask]\n\ntrain_sentences = load_data(train_df, sort=True, tokenizer=tokenizer)\ntrain_batches = build_batches(train_sentences, batch_size=TRAIN_BATCH_SIZE)\ntrain_dataset = TextDataset(train_batches, tokenizer, max_length=MAX_LEN)\n\nvalid_sentences = load_data(valid_df, sort=True, tokenizer=tokenizer)\nvalid_batches = build_batches(valid_sentences, batch_size=VALID_BATCH_SIZE)\nvalid_dataset = TextDataset(valid_batches, tokenizer, max_length=MAX_LEN)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _run():\n    xm.master_print('Starting Run ...')\n    \n    train_sampler = DistributedSampler(\n        train_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False\n    )\n    \n    train_data_loader = DataLoader(\n        train_dataset,\n        collate_fn = collate_batch,\n        batch_size=TRAIN_BATCH_SIZE,\n        sampler=train_sampler,\n        drop_last=True,\n        num_workers=0\n    )\n    xm.master_print('Train Loader Created.')\n    \n    valid_sampler = DistributedSampler(\n        valid_dataset,\n        num_replicas=xm.xrt_world_size(),\n        rank=xm.get_ordinal(),\n        shuffle=False\n    )\n    \n    valid_data_loader = DataLoader(\n        valid_dataset,\n        collate_fn=collate_batch,\n        batch_size=VALID_BATCH_SIZE,\n        sampler=valid_sampler,\n        drop_last=True,\n        num_workers=0\n    )\n    xm.master_print('Valid Loader Created.')\n    \n    num_train_steps = int(len(train_df) / TRAIN_BATCH_SIZE / xm.xrt_world_size())\n    device = xm.xla_device()\n    model = WRAPPED_MODEL.to(device)\n    xm.master_print('Done Model Loading.')\n    optimizer = get_model_optimizer(model)\n    scheduler = get_cosine_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps = 0,\n        num_training_steps = num_train_steps * EPOCHS\n    )\n    xm.master_print(f'Num Train Steps= {num_train_steps}, XRT World Size= {xm.xrt_world_size()}.')\n    \n    for epoch in range(EPOCHS):\n        para_loader = pl.ParallelLoader(train_data_loader, [device])\n        xm.master_print('Parallel Loader Created. Training ...')\n        train_loop_fn(para_loader.per_device_loader(device),\n                      model,  \n                      optimizer, \n                      device, \n                      scheduler, \n                      epoch\n                     )\n        \n        xm.master_print(\"Finished training epoch {}\".format(epoch))\n            \n        para_loader = pl.ParallelLoader(valid_data_loader, [device])\n        xm.master_print('Parallel Loader Created. Validating ...')\n        eval_loop_fn(para_loader.per_device_loader(device), \n                     model,  \n                     device\n                    )\n        \n        # Serialized and Memory Reduced Model Saving\n        if epoch == EPOCHS-1:\n            xm.master_print('Saving Model ..')\n            xser.save(model.state_dict(), \"model.bin\", master_only=True)\n            xm.master_print('Model Saved.')\n            \n    if METRICS_DEBUG:\n      xm.master_print(met.metrics_report(), flush=True)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def _mp_fn(rank, flags):\n    # torch.set_default_tensor_type('torch.FloatTensor')\n    _run()\n\nFLAGS={}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')","execution_count":16,"outputs":[{"output_type":"stream","text":"Starting Run ...\nTrain Loader Created.\nValid Loader Created.\nDone Model Loading.\nNum Train Steps= 90, XRT World Size= 8.\nParallel Loader Created. Training ...\n[xla:7]Train:  Epoch: [0][ 0/90]\tTime 19.825 (19.825)\tData  0.070 ( 0.070)\tLoss 1.0703e+00 (1.0703e+00)\tAcc@1  43.75 ( 43.75)\n[xla:3]Train:  Epoch: [0][ 0/90]\tTime 16.296 (16.296)\tData  0.085 ( 0.085)\tLoss 1.0391e+00 (1.0391e+00)\tAcc@1  62.50 ( 62.50)\n[xla:4]Train:  Epoch: [0][ 0/90]\tTime 12.814 (12.814)\tData  0.075 ( 0.075)\tLoss 1.2031e+00 (1.2031e+00)\tAcc@1  37.50 ( 37.50)\n[xla:6]Train:  Epoch: [0][ 0/90]\tTime  2.306 ( 2.306)\tData  0.080 ( 0.080)\tLoss 1.1562e+00 (1.1562e+00)\tAcc@1  31.25 ( 31.25)\n[xla:0]Train:  Epoch: [0][ 0/90]\tTime 27.359 (27.359)\tData  0.307 ( 0.307)\tLoss 1.4219e+00 (1.4219e+00)\tAcc@1  12.50 ( 12.50)\n[xla:5]Train:  Epoch: [0][ 0/90]\tTime 23.773 (23.773)\tData  0.069 ( 0.069)\tLoss 1.2734e+00 (1.2734e+00)\tAcc@1  25.00 ( 25.00)\n[xla:2]Train:  Epoch: [0][ 0/90]\tTime  9.538 ( 9.538)\tData  0.068 ( 0.068)\tLoss 1.2188e+00 (1.2188e+00)\tAcc@1  37.50 ( 37.50)\n[xla:1]Train:  Epoch: [0][ 0/90]\tTime  5.782 ( 5.782)\tData  0.079 ( 0.079)\tLoss 1.2812e+00 (1.2812e+00)\tAcc@1  43.75 ( 43.75)\n[xla:2]Train:  Epoch: [0][10/90]\tTime 66.982 (54.365)\tData 38.407 (28.954)\tLoss 1.1016e+00 (1.1470e+00)\tAcc@1  31.25 ( 32.95)\n[xla:4]Train:  Epoch: [0][10/90]\tTime 66.980 (54.665)\tData 38.401 (28.964)\tLoss 1.1562e+00 (1.1655e+00)\tAcc@1  25.00 ( 33.52)\n[xla:5]Train:  Epoch: [0][10/90]\tTime 66.997 (55.661)\tData 38.411 (28.964)\tLoss 1.0781e+00 (1.1825e+00)\tAcc@1  50.00 ( 31.25)\n[xla:3]Train:  Epoch: [0][10/90]\tTime 66.994 (54.983)\tData 38.406 (28.956)\tLoss 1.1094e+00 (1.1236e+00)\tAcc@1  31.25 ( 35.80)\n[xla:6]Train:  Epoch: [0][10/90]\tTime 66.990 (53.710)\tData 38.405 (28.951)\tLoss 1.1484e+00 (1.1634e+00)\tAcc@1  37.50 ( 27.27)\n[xla:7]Train:  Epoch: [0][10/90]\tTime 67.001 (55.304)\tData 38.405 (28.964)\tLoss 1.2500e+00 (1.1413e+00)\tAcc@1  12.50 ( 38.07)\n[xla:1]Train:  Epoch: [0][10/90]\tTime 66.989 (54.026)\tData 38.361 (28.929)\tLoss 1.1328e+00 (1.1349e+00)\tAcc@1  18.75 ( 35.80)\n[xla:0]Train:  Epoch: [0][10/90]\tTime 66.989 (55.991)\tData 38.359 (28.946)\tLoss 1.1172e+00 (1.1882e+00)\tAcc@1  43.75 ( 30.68)\n[xla:4]Train:  Epoch: [0][20/90]\tTime 59.580 (49.174)\tData 29.034 (25.776)\tLoss 1.2109e+00 (1.1525e+00)\tAcc@1  25.00 ( 31.85)\n[xla:7]Train:  Epoch: [0][20/90]\tTime 59.573 (49.509)\tData 28.992 (25.777)\tLoss 1.1328e+00 (1.1287e+00)\tAcc@1  25.00 ( 37.80)\n[xla:6]Train:  Epoch: [0][20/90]\tTime 59.589 (48.674)\tData 29.001 (25.778)\tLoss 1.0703e+00 (1.1496e+00)\tAcc@1  37.50 ( 30.36)\n[xla:3]Train:  Epoch: [0][20/90]\tTime 59.585 (49.340)\tData 29.000 (25.778)\tLoss 1.1328e+00 (1.1269e+00)\tAcc@1  43.75 ( 33.63)\n[xla:2]Train:  Epoch: [0][20/90]\tTime 59.588 (49.018)\tData 29.026 (25.775)\tLoss 1.0781e+00 (1.1425e+00)\tAcc@1  43.75 ( 33.04)\n[xla:5]Train:  Epoch: [0][20/90]\tTime 59.593 (49.697)\tData 29.020 (25.775)\tLoss 1.2422e+00 (1.1499e+00)\tAcc@1  18.75 ( 35.71)\n[xla:0]Train:  Epoch: [0][20/90]\tTime 59.582 (49.868)\tData 28.966 (25.757)\tLoss 1.1172e+00 (1.1700e+00)\tAcc@1  50.00 ( 31.25)\n[xla:1]Train:  Epoch: [0][20/90]\tTime 59.582 (48.839)\tData 28.929 (25.746)\tLoss 1.0078e+00 (1.1283e+00)\tAcc@1  56.25 ( 32.74)\n","name":"stdout"},{"output_type":"error","ename":"Exception","evalue":"process 2 terminated with signal SIGKILL","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-f22262e72f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mp_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         start_method=start_method)\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m                 raise Exception(\n\u001b[1;32m    107\u001b[0m                     \u001b[0;34m\"process %d terminated with signal %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m                 )\n\u001b[1;32m    110\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: process 2 terminated with signal SIGKILL"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}