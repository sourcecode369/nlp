{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bi-LSTM Predict Next Word in Long Sentence.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNu2oAhrttSz0ik2tIx6P0Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcecode369/transformers-tutorials/blob/master/lstm/Bi_LSTM_Predict_Next_Word_in_Long_Sentence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Iuey67JLU0o"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1WVBJiHLf3b"
      },
      "source": [
        "sentence = (\n",
        "            \"Artificial Intelligence involves using computers to do things that traditionally require human intelligence \"\n",
        "            \"This means creating algorithms to classify analyze and draw predictions from data \"\n",
        "            \"It also involves acting on data learning from new data and improving over time \"\n",
        "            \"Just like a tiny human child growing up into a smarter human adult \"\n",
        "            \"And like humans AI is not perfect \"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSLL1dc1M3KX"
      },
      "source": [
        "word_dict = {w:i for i, w in enumerate(list(set(sentence.split())))}\n",
        "number_dict = {i:w for i, w in enumerate(list(set(sentence.split())))}\n",
        "n_class = len(word_dict)\n",
        "n_hidden = 10\n",
        "max_len = len(sentence.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mySAQbxlmfNj"
      },
      "source": [
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BiLSTM, self).__init__()\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=n_class, hidden_size=n_hidden, bidirectional=True)\n",
        "        self.W = nn.Linear(n_hidden * 2, n_class, bias=False)\n",
        "        self.b = nn.Parameter(torch.ones([n_class]))\n",
        "\n",
        "    def forward(self, X):\n",
        "        input = X.transpose(0, 1)  # input : [n_step, batch_size, n_class]\n",
        "\n",
        "        hidden_state = torch.zeros(1*2, len(X), n_hidden)   # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
        "        cell_state = torch.zeros(1*2, len(X), n_hidden)     # [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
        "\n",
        "        outputs, (_, _) = self.lstm(input, (hidden_state, cell_state))\n",
        "        outputs = outputs[-1]  # [batch_size, n_hidden]\n",
        "        model = self.W(outputs) + self.b  # model : [batch_size, n_class]\n",
        "        return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbf2B9mMntms"
      },
      "source": [
        "def make_batch():\n",
        "    input_batch = []\n",
        "    target_batch = []\n",
        "\n",
        "    words = sentence.split()\n",
        "    for i, word in enumerate(words[:-1]):\n",
        "        input = [word_dict[n] for n in words[:(i + 1)]]\n",
        "        input = input + [0] * (max_len - len(input))\n",
        "        target = word_dict[words[i + 1]]\n",
        "        input_batch.append(np.eye(n_class)[input])\n",
        "        target_batch.append(target)\n",
        "\n",
        "    return input_batch, target_batch          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpAeuH72rsjH"
      },
      "source": [
        "input_batch, target_batch = make_batch()\n",
        "input_batch = torch.FloatTensor(input_batch)\n",
        "target_batch = torch.LongTensor(target_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMj-JauVtVeR"
      },
      "source": [
        "model = BiLSTM()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEKrQRXqsy4o",
        "outputId": "4bd7addd-d583-4978-8819-ddd1fbe92096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "for epoch in range(5000):\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(input_batch)\n",
        "    loss = criterion(outputs, target_batch)\n",
        "    if (epoch + 1) % 500 == 0:\n",
        "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0500 cost = 3.096175\n",
            "Epoch: 1000 cost = 2.469000\n",
            "Epoch: 1500 cost = 2.287508\n",
            "Epoch: 2000 cost = 1.783772\n",
            "Epoch: 2500 cost = 1.940998\n",
            "Epoch: 3000 cost = 1.487094\n",
            "Epoch: 3500 cost = 1.375398\n",
            "Epoch: 4000 cost = 1.300185\n",
            "Epoch: 4500 cost = 1.247313\n",
            "Epoch: 5000 cost = 1.199682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKUJO5Egt-oZ",
        "outputId": "c5c79e43-f93b-4cce-f460-e04333abd1bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "predict = model(input_batch).data.max(1, keepdim=True)[1]\n",
        "print(sentence)\n",
        "print([number_dict[n.item()] for n in predict.squeeze()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Artificial Intelligence involves using computers to do things that traditionally require human intelligence This means creating algorithms to classify analyze and draw predictions from data It also involves acting on data learning from new data and improving over time Just like a tiny human child growing up into a smarter human adult And like humans AI is not perfect \n",
            "['to', 'to', 'to', 'new', 'to', 'draw', 'that', 'that', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'to', 'data', 'that', 'from', 'from', 'data', 'from', 'also', 'involves', 'also', 'data', 'data', 'from', 'from', 'new', 'data', 'data', 'improving', 'over', 'time', 'time', 'like', 'a', 'tiny', 'human', 'child', 'growing', 'up', 'into', 'a', 'smarter', 'human', 'adult', 'And', 'like', 'humans', 'AI', 'is', 'not', 'perfect']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}